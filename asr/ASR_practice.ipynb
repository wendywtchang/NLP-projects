{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wendywtchang/NLP-projects/blob/master/asr/ASR_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2rxoev5bwJa",
        "outputId": "9fe35236-e177-4d75-d28c-28d4432b638e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_NS58O8cs2F"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9MOFTnQcImx",
        "outputId": "e085d06f-51fd-4959-e6a4-3bc0818c36f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ASR\n",
            "total 5938\n",
            "-rw------- 1 root  741530 Feb  4 19:43  ASRfromScratch.ipynb\n",
            "-rw------- 1 root    5075 Feb  4 21:28  ASR_practice.ipynb\n",
            "-rw------- 1 root  359156 Feb  4 19:40  ASR_seame.ipynb\n",
            "-rw------- 1 root   19353 Feb  4 09:49  HyperPyYaml.ipynb\n",
            "-rw------- 1 root  521318 Feb  4 10:05  Introduction_to_SpeechBrain.ipynb\n",
            "-rw------- 1 root  878758 Feb  3 21:10 'Kaldi ASR install example.ipynb'\n",
            "lrw------- 1 root      24 Feb  4 16:26  \u001b[0m\u001b[01;36mmini_librispeech_prepare.py\u001b[0m -> mini_librispeech_prepare\n",
            "-rw------- 1 root  746347 Feb  3 20:52  simple_audio.ipynb\n",
            "drwx------ 2 root    4096 Feb  4 11:15  \u001b[01;34mspeechbrain\u001b[0m/\n",
            "-rw------- 1 root 2802266 Feb  4 10:12  What_can_I_do.ipynb\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/ASR\n",
        "%ll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TjFUeL3eb5kg"
      },
      "outputs": [],
      "source": [
        "# #Local installation\n",
        "# !git clone https://github.com/speechbrain/speechbrain/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2XL7WSKcnP_",
        "outputId": "e42fd63a-7782-49db-d644-a45a0d122db9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ASR/speechbrain\n",
            "total 69\n",
            "-rw------- 1 root  1047 Feb  4 11:15 conftest.py\n",
            "drwx------ 2 root  4096 Feb  4 11:15 \u001b[0m\u001b[01;34mdocs\u001b[0m/\n",
            "-rw------- 1 root 11357 Feb  4 11:15 LICENSE\n",
            "-rw------- 1 root    79 Feb  4 11:15 lint-requirements.txt\n",
            "-rw------- 1 root   239 Feb  4 11:15 pyproject.toml\n",
            "-rw------- 1 root   126 Feb  4 11:15 pytest.ini\n",
            "-rw------- 1 root 16695 Feb  4 11:15 README.md\n",
            "drwx------ 2 root  4096 Feb  4 11:15 \u001b[01;34mrecipes\u001b[0m/\n",
            "-rw------- 1 root   256 Feb  4 11:16 requirements.txt\n",
            "drwx------ 2 root  4096 Feb  4 11:16 \u001b[01;34msamples\u001b[0m/\n",
            "drwx------ 2 root  4096 Feb  4 15:26 \u001b[01;34mseame\u001b[0m/\n",
            "-rw------- 1 root  1153 Feb  4 11:16 setup.py\n",
            "drwx------ 2 root  4096 Feb  4 11:16 \u001b[01;34mspeechbrain\u001b[0m/\n",
            "drwx------ 2 root  4096 Feb  4 11:19 \u001b[01;34mspeechbrain.egg-info\u001b[0m/\n",
            "drwx------ 2 root  4096 Feb  4 11:16 \u001b[01;34mtemplates\u001b[0m/\n",
            "drwx------ 2 root  4096 Feb  4 11:16 \u001b[01;34mtests\u001b[0m/\n",
            "drwx------ 2 root  4096 Feb  4 11:16 \u001b[01;34mtools\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/ASR/speechbrain/\n",
        "%ll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6MosbhmcwcQ",
        "outputId": "aade20c6-8144-46e4-d3b1-27329872588f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignoring SoundFile: markers 'sys_platform == \"win32\"' don't match your environment\n",
            "Collecting black==19.10b0\n",
            "  Downloading black-19.10b0-py36-none-any.whl (97 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 51 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 61 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 71 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 81 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 92 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 97 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting flake8==3.7.9\n",
            "  Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 9.6 MB/s \n",
            "\u001b[?25hCollecting pycodestyle==2.5.0\n",
            "  Downloading pycodestyle-2.5.0-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 9.2 MB/s \n",
            "\u001b[?25hCollecting pytest==5.4.1\n",
            "  Downloading pytest-5.4.1-py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 72.2 MB/s \n",
            "\u001b[?25hCollecting yamllint==1.23.0\n",
            "  Downloading yamllint-1.23.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting huggingface_hub>=0.0.6\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.3 MB/s \n",
            "\u001b[?25hCollecting hyperpyyaml>=0.0.1\n",
            "  Downloading HyperPyYAML-1.0.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (21.3)\n",
            "Collecting pre-commit>=2.3.0\n",
            "  Downloading pre_commit-2.17.0-py2.py3-none-any.whl (195 kB)\n",
            "\u001b[K     |████████████████████████████████| 195 kB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.4.1)\n",
            "Collecting sentencepiece>=0.1.91\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 62.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<=1.10.1,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchaudio<=0.10.1,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.10.0+cu111)\n",
            "Requirement already satisfied: tqdm>=4.42.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.62.3)\n",
            "Collecting typed-ast>=1.4.0\n",
            "  Downloading typed_ast-1.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 59.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->-r lint-requirements.txt (line 1)) (0.10.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->-r lint-requirements.txt (line 1)) (2019.12.20)\n",
            "Collecting pathspec<1,>=0.6\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->-r lint-requirements.txt (line 1)) (1.4.4)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->-r lint-requirements.txt (line 1)) (21.4.0)\n",
            "Requirement already satisfied: click>=6.5 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0->-r lint-requirements.txt (line 1)) (7.1.2)\n",
            "Collecting entrypoints<0.4.0,>=0.3.0\n",
            "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting pyflakes<2.2.0,>=2.1.0\n",
            "  Downloading pyflakes-2.1.1-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 9.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.1->-r lint-requirements.txt (line 4)) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.1->-r lint-requirements.txt (line 4)) (4.10.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.1->-r lint-requirements.txt (line 4)) (8.12.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.1->-r lint-requirements.txt (line 4)) (1.11.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from yamllint==1.23.0->-r lint-requirements.txt (line 5)) (3.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (3.10.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (3.4.2)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 72.8 MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml>=0.15\n",
            "  Downloading ruamel.yaml-0.17.20-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->-r requirements.txt (line 6)) (3.0.7)\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.13.0-py2.py3-none-any.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 74.9 MB/s \n",
            "\u001b[?25hCollecting identify>=1.0.0\n",
            "  Downloading identify-2.4.8-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==5.4.1->-r lint-requirements.txt (line 4)) (3.7.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 78.9 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 74.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit>=2.3.0->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface_hub>=0.0.6->-r requirements.txt (line 2)) (3.0.4)\n",
            "Installing collected packages: ruamel.yaml.clib, platformdirs, distlib, virtualenv, typed-ast, ruamel.yaml, pyyaml, pyflakes, pycodestyle, pluggy, pathspec, nodeenv, mccabe, identify, entrypoints, cfgv, yamllint, sentencepiece, pytest, pre-commit, hyperpyyaml, huggingface-hub, flake8, black\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: entrypoints\n",
            "    Found existing installation: entrypoints 0.4\n",
            "    Uninstalling entrypoints-0.4:\n",
            "      Successfully uninstalled entrypoints-0.4\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed black-19.10b0 cfgv-3.3.1 distlib-0.3.4 entrypoints-0.3 flake8-3.7.9 huggingface-hub-0.4.0 hyperpyyaml-1.0.0 identify-2.4.8 mccabe-0.6.1 nodeenv-1.6.0 pathspec-0.9.0 platformdirs-2.4.1 pluggy-0.13.1 pre-commit-2.17.0 pycodestyle-2.5.0 pyflakes-2.1.1 pytest-5.4.1 pyyaml-6.0 ruamel.yaml-0.17.20 ruamel.yaml.clib-0.2.6 sentencepiece-0.1.96 typed-ast-1.5.2 virtualenv-20.13.0 yamllint-1.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmnqWb2Jc8NO",
        "outputId": "ebfa7173-6e85-4f15-e032-5a7df076d20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/drive/MyDrive/ASR/speechbrain\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (0.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.19.5)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (0.10.0+cu111)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (0.1.96)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (21.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.1.0)\n",
            "Requirement already satisfied: torch<=1.11,>=1.7 in /usr/local/lib/python3.7/dist-packages (from speechbrain==0.5.11) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.11,>=1.7->speechbrain==0.5.11) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain==0.5.11) (4.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain==0.5.11) (3.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain==0.5.11) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain==0.5.11) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->speechbrain==0.5.11) (3.0.7)\n",
            "Requirement already satisfied: ruamel.yaml>=0.15 in /usr/local/lib/python3.7/dist-packages (from hyperpyyaml->speechbrain==0.5.11) (0.17.20)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.15->hyperpyyaml->speechbrain==0.5.11) (0.2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->speechbrain==0.5.11) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain==0.5.11) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain==0.5.11) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain==0.5.11) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain==0.5.11) (2.10)\n",
            "Installing collected packages: speechbrain\n",
            "  Running setup.py develop for speechbrain\n",
            "Successfully installed speechbrain\n"
          ]
        }
      ],
      "source": [
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT1KvxCb-LGI",
        "outputId": "6fab266d-4b7d-4e29-e38b-2d624f8d2056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speechbrain\n",
            "  Downloading speechbrain-0.5.11-py3-none-any.whl (408 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 32.1 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 61 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 71 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 81 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 92 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 102 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 112 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 122 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 133 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 143 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 153 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 163 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 174 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 184 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 194 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 204 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 215 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 225 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 235 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 245 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 256 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 266 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 276 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 286 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 296 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 307 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 317 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 327 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 337 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 348 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 358 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 368 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 378 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 389 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 399 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 408 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.1.0)\n",
            "Requirement already satisfied: torch<=1.11,>=1.7 in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.10.0+cu111)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from speechbrain) (21.3)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.10.0+cu111)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.1.96)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from speechbrain) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.11,>=1.7->speechbrain) (3.10.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (4.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (3.4.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->speechbrain) (3.0.7)\n",
            "Requirement already satisfied: ruamel.yaml>=0.15 in /usr/local/lib/python3.7/dist-packages (from hyperpyyaml->speechbrain) (0.17.20)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.15->hyperpyyaml->speechbrain) (0.2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->speechbrain) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2.10)\n",
            "Installing collected packages: speechbrain\n",
            "Successfully installed speechbrain-0.5.11\n"
          ]
        }
      ],
      "source": [
        "!pip install speechbrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI4RBnu7dy3P"
      },
      "source": [
        "# Steps\n",
        "- Data preparation\n",
        "- Train a tokenizer\n",
        "- Train a language model\n",
        "- Train a speech recognizer\n",
        "- Test the recognizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMBoZ1KoeFeO"
      },
      "source": [
        "# 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPjyBqW_DKkz"
      },
      "source": [
        "# 2. Train a Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp9oa0f0dfK5",
        "outputId": "0dd827ec-6ed2-41b2-cbca-1973cc0488a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ASR/speechbrain/templates/speech_recognition/Tokenizer\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/ASR/speechbrain/templates/speech_recognition/Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWCB-xfP9iOM",
        "outputId": "d6f8576e-d57c-4a1c-900d-d959d8895b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: ./save\n",
            "mini_librispeech_prepare - Preparation completed in previous run, skipping.\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer is already trained.\n",
            "speechbrain.tokenizers.SentencePiece - ==== Loading Tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer path: ./save/1000_unigram.model\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer vocab_size: 1000\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer type: unigram\n",
            "speechbrain.tokenizers.SentencePiece - ==== Accuracy checking for recovering text from tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - recover words from: ../train.json\n",
            "speechbrain.tokenizers.SentencePiece - Wrong recover words: 0\n",
            "speechbrain.tokenizers.SentencePiece - accuracy recovering words: 1.0\n",
            "speechbrain.tokenizers.SentencePiece - ==== Accuracy checking for recovering text from tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - recover words from: ../valid.json\n",
            "speechbrain.tokenizers.SentencePiece - Wrong recover words: 0\n",
            "speechbrain.tokenizers.SentencePiece - accuracy recovering words: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Tokenizer\n",
        "!python train.py tokenizer.yaml\n",
        "#create experiment folder ./save\n",
        "#download train, dev, test dataset of minilibrispeech\n",
        "#ceate json file for train, dev, test\n",
        "#Train tokenizer with type:unigram\n",
        "#Extract words sequences from:../train.json\n",
        "#Text file created at: ../train.txt\n",
        "#sentencepiece_trainer -> trainer_spec (some config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veoCskhtBdi3"
      },
      "source": [
        "- the tokenizer generates the 1000_unigram.model under the save file\n",
        "- we can use ti model to tokenize any input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdCz4Kxg-G81",
        "outputId": "98a46990-43be-423c-b75c-f8b40d5b3686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁THE', '▁CITY', '▁OF', '▁MON', 'T', 'RE', 'AL']\n",
            "['▁THE', '▁CITY', '▁OF', '▁T', 'A', 'IP', 'E', 'I']\n",
            "[1, 658, 9, 486, 8, 63, 50]\n",
            "[1, 658, 9, 54, 40, 292, 5, 33]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sentencepiece as spm\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(\"/content/drive/MyDrive/ASR/speechbrain/templates/speech_recognition/Tokenizer/save/1000_unigram.model\")\n",
        "\n",
        "#Encode as pieces\n",
        "print(sp.encode_as_pieces('THE CITY OF MONTREAL'))\n",
        "print(sp.encode_as_pieces('THE CITY OF TAIPEI'))\n",
        "\n",
        "\n",
        "#Encode as ids\n",
        "print(sp.encode_as_ids('THE CITY OF MONTREAL'))\n",
        "print(sp.encode_as_ids('THE CITY OF TAIPEI'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34muwXKvDP8I"
      },
      "source": [
        "# 3. Train a Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4NCRwMkDTIP",
        "outputId": "ddaf9926-e911-468f-c530-467d97c44b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\n",
            "\u001b[K     |████████████████████████████████| 311 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 60.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.10.1)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 77.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 69.6 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 73.8 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.11)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, datasets\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.18.3 frozenlist-1.3.0 fsspec-2022.1.0 multidict-6.0.2 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ-EBYW4DTK7",
        "outputId": "2c314ff2-3b51-49c0-f012-55fbc6dcf697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ASR/speechbrain/templates/speech_recognition/LM\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/ASR/speechbrain/templates/speech_recognition/LM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4P_E7TeDTNX",
        "outputId": "2660f671-8d02-487f-b023-bd1a2d9ce275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/RNNLM/\n",
            "root - generating datasets...\n",
            "datasets.builder - Using custom data configuration default-9abd478736457ce5\n",
            "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-9abd478736457ce5/0.0.0/08f6fb1dd2dab0a18ea441c359e1d63794ea8cb53e7863e6edf8fc5655e47ec4...\n",
            "100% 3/3 [00:00<00:00, 3405.39it/s]\n",
            "100% 3/3 [00:00<00:00, 115.37it/s]\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-9abd478736457ce5/0.0.0/08f6fb1dd2dab0a18ea441c359e1d63794ea8cb53e7863e6edf8fc5655e47ec4. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 475.44it/s]\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 4.4M trainable parameters in LM\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/RNNLM/save/CKPT+2022-02-04+14-20-49+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/RNNLM/save/CKPT+2022-02-04+14-20-49+00\n",
            "100% 151/151 [00:00<00:00, 662.54it/s]\n",
            "speechbrain.utils.train_logger - Epoch loaded: 20 - test loss: 5.96e-07\n"
          ]
        }
      ],
      "source": [
        "#train LM\n",
        "#here we fix the RNNLM.yaml line 66 (path does not exist)\n",
        "!python train.py RNNLM.yaml #--device='cpu'\n",
        "#check results in LM/results/RNNLM\n",
        "#saved model checkpoint in LM/results/RNNLM/save - it will save the lastest one and the best one (if there are two models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBiYU22ZM1o0"
      },
      "source": [
        "# 4. Train a Speech Recognizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lIzA0FBDTQI",
        "outputId": "a56c8b40-22ee-4e5a-8ac0-3071fa981faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ASR/speechbrain/templates/speech_recognition/ASR\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/ASR/speechbrain/templates/speech_recognition/ASR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "seLaZCBfDTVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175c2582-80b3-4b98-d0c7-0c31968f264f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "../data/rirs_noises.zip exists. Skipping download\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/CRDNN_BPE_960h_LM/2602\n",
            "mini_librispeech_prepare - Preparation completed in previous run, skipping.\n",
            "speechbrain.pretrained.fetching - Fetch lm.ckpt: Using existing file/symlink in results/CRDNN_BPE_960h_LM/2602/save/lm.ckpt.\n",
            "speechbrain.pretrained.fetching - Fetch tokenizer.ckpt: Using existing file/symlink in results/CRDNN_BPE_960h_LM/2602/save/tokenizer.ckpt.\n",
            "speechbrain.pretrained.fetching - Fetch asr.ckpt: Using existing file/symlink in results/CRDNN_BPE_960h_LM/2602/save/model.ckpt.\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: lm, tokenizer, model\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 173.0M trainable parameters in ASR\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/CRDNN_BPE_960h_LM/2602/save/CKPT+2022-02-04+20-34-03+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/CRDNN_BPE_960h_LM/2602/save/CKPT+2022-02-04+16-36-20+00\n",
            "100% 1310/1310 [1:07:30<00:00,  3.09s/it]\n",
            "speechbrain.utils.train_logger - Epoch loaded: 4 - test loss: 1.34, test CER: 79.35, test WER: 83.21\n"
          ]
        }
      ],
      "source": [
        "!python train.py train.yaml --batch_size=2 #--device='cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bQzLezpjDTX1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5__4zz1BDTa6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ogND1WuGATJK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ASR_practice.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOqrMw8U621FrTqxb10fzPQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}